{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建索引\n",
    "# result = es.indices.create(index='news', ignore=400)\n",
    "\n",
    "#删除索引\n",
    "# result = es.indices.delete(index='news', ignore=[400, 404])\n",
    "\n",
    "#插入数据\n",
    "# es.create(index='news', doc_type='politics', id=1, body=data)\n",
    "# es.index(index='news', doc_type='politics', body=data)  \n",
    "\n",
    "#更新数据\n",
    "# es.update(index='news', doc_type='politics', body=data, id=1)\n",
    "# es.index(index='news', doc_type='politics', body=data, id=1)\n",
    "\n",
    "#删除数据（指定需要删除的数据 id 即可）\n",
    "# es.delete(index='news', doc_type='politics', id=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_index(index_name):\n",
    "#     from elasticsearch import Elasticsearch\n",
    "    \n",
    "#     es = Elasticsearch()\n",
    "#     body = {\n",
    "#         \"mappings\": {\n",
    "#             \"properties\": {\n",
    "#                 \"Title\": {\n",
    "#                     \"type\": \"text\",\n",
    "#                     \"analyzer\": \"ik_max_word\"\n",
    "#                 },\n",
    "#                 \"Time\": {\n",
    "#                     \"type\": \"text\"\n",
    "#                 },\n",
    "#                 \"Link\": {\n",
    "#                     \"type\": \"text\"\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     result = es.indices.create(index=index_name, body=body, ignore=400)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#删除索引\n",
    "# es.indices.delete(index='news', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(i):\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    header = {\n",
    "        'Referer':'https://www.huawei.com/cn/',\n",
    "        'User-Agent':'Mozilla/5.0',\n",
    "        'Cookie': 'HMF_CI=a84038a77dca61be2d2af9f4cf312263ed94089f73d6af86f051663dcf66eeaf00; _ga=GA1.2.1917284659.1606551520; atuserid=%7B%22name%22%3A%22atuserid%22%2C%22val%22%3A%2245d8650b-a969-4851-816c-9e292fc91d56%22%2C%22options%22%3A%7B%22end%22%3A%222021-12-30T08%3A19%3A20.456Z%22%2C%22path%22%3A%22%2F%22%7D%7D; atidvisitor=%7B%22name%22%3A%22atidvisitor%22%2C%22val%22%3A%7B%22vrn%22%3A%22-609951-%22%7D%2C%22options%22%3A%7B%22path%22%3A%22%2F%22%2C%22session%22%3A15724800%2C%22end%22%3A15724800%7D%7D; channel_name=baidu; channel_category=search; _gid=GA1.2.714551871.1607502748; cbg1#lang=zh; ASP.NET_SessionId=lss32rifeao4nfuooxh113ky; Hm_lvt_48e5a2ca327922f1ee2bb5ea69bdd0a6=1606551522,1607502748,1607505225,1607505256; Hm_lpvt_48e5a2ca327922f1ee2bb5ea69bdd0a6=1607505256; _Jo0OQK=1BB24D7BB6DF1D7FC3E6BFB62FACA4C9442E612415AE529C585286CCEC92896697E00BA8C07D03CD43F748C99CFFD1F496DA96B805131FD76479183464E2F7D6CCFFEBDAFEB1BC7D84ABDC7B30FBAF0A756BDC7B30FBAF0A7560424176440DCD66EGJ1Z1MQ==; utag_main=v_id:01760deebd9f001532b7403a17a403082001a07a0086e$_sn:2$_se:61$_ss:0$_st:1607507078035$dc_visit:2$ses_id:1607502747152%3Bexp-session$_pn:17%3Bexp-session$dc_event:55%3Bexp-session$dc_region:ap-northeast-1%3Bexp-session'\n",
    "    }\n",
    "    url = 'https://www.huawei.com/cn/news?d=ws'\n",
    "    data = {\n",
    "        'PageIndex':i\n",
    "    }\n",
    "    response = requests.post(url,data=data,headers=header)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_data):\n",
    "    import json\n",
    "    \n",
    "    dataList = []\n",
    "    res = json.loads(json_data)\n",
    "    for i in range(len(res[\"Result\"][\"ResultList\"])):\n",
    "        i_dict = {}\n",
    "        i_dict['Title'] = res[\"Result\"][\"ResultList\"][i][\"Title\"]\n",
    "        i_dict['Time'] = res[\"Result\"][\"ResultList\"][i][\"Time\"]\n",
    "        i_dict['Link'] = 'https://www.huawei.com/' + res[\"Result\"][\"ResultList\"][i][\"MoreLink\"]\n",
    "        dataList.append(i_dict)\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入要爬取的页数：\n",
      "\n",
      "42\n",
      "正在爬取第1页......\n",
      "第1页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第2页......\n",
      "第2页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第3页......\n",
      "第3页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第4页......\n",
      "第4页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第5页......\n",
      "第5页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第6页......\n",
      "第6页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第7页......\n",
      "第7页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第8页......\n",
      "第8页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第9页......\n",
      "第9页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第10页......\n",
      "第10页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第11页......\n",
      "第11页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第12页......\n",
      "第12页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第13页......\n",
      "第13页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第14页......\n",
      "第14页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第15页......\n",
      "第15页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第16页......\n",
      "第16页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第17页......\n",
      "第17页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第18页......\n",
      "第18页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第19页......\n",
      "第19页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第20页......\n",
      "第20页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第21页......\n",
      "第21页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第22页......\n",
      "第22页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第23页......\n",
      "第23页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第24页......\n",
      "第24页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第25页......\n",
      "第25页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第26页......\n",
      "第26页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第27页......\n",
      "第27页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第28页......\n",
      "第28页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第29页......\n",
      "第29页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第30页......\n",
      "第30页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第31页......\n",
      "第31页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第32页......\n",
      "第32页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第33页......\n",
      "第33页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第34页......\n",
      "第34页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第35页......\n",
      "第35页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第36页......\n",
      "第36页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第37页......\n",
      "第37页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第38页......\n",
      "第38页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第39页......\n",
      "第39页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第40页......\n",
      "第40页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第41页......\n",
      "第41页爬取完成！！！\n",
      "已保存！！！\n",
      "正在爬取第42页......\n",
      "第42页爬取完成！！！\n",
      "已保存！！！\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    es = Elasticsearch()\n",
    "    body = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Title\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"ik_max_word\"\n",
    "                },\n",
    "                \"Time\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"Link\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index='news', body=body, ignore=400)\n",
    "    \n",
    "    print('输入要爬取的页数：\\n')\n",
    "    pageNum = int(input())\n",
    "    \n",
    "    for i in range(pageNum):\n",
    "        \n",
    "        print('正在爬取第' + str(i+1) + '页......')\n",
    "        json_data = get_json(i+1)\n",
    "        print('第' + str(i+1) + '页爬取完成！！！')\n",
    "        \n",
    "        dataList = load_json(json_data)\n",
    "        for data in dataList:\n",
    "            es.index(index='news', body=data)\n",
    "        print('已保存！！！')\n",
    "        \n",
    "        time.sleep(random.randint(3,8))\n",
    "    print('completed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
